{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMBdKOGTlRJzLR3tZf7u7zL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woodRock/deep-learning-goodfellow/blob/main/chapter_7_regularization_for_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 7 | Regularization for Deep Learning\n",
        "\n",
        "References:\n",
        "1. Hinton, G. E. (2012). Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580.\n",
        "2. Srebro, N., & Shraibman, A. (2005, June). Rank, trace-norm and max-norm. In International conference on computational learning theory (pp. 545-560). Springer Berlin Heidelberg.\n",
        "3. Sietsma, J., & Dow, R. J. (1991). Creating artificial neural networks that generalize. Neural networks, 4(1), 67-79.\n",
        "4. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1), 1929-1958.\n",
        "\n",
        "\n",
        "We defined regularization as \"any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error\"."
      ],
      "metadata": {
        "id": "oHF0W8NFHiVm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_THe7whOHBvn",
        "outputId": "046e95fb-7792-4cd5-e188-deafc089bbbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I: 0 \t accuracy: 0.123 \t test accuracy: 0.231\n",
            "I: 10 \t accuracy: 0.625 \t test accuracy: 0.705\n",
            "I: 20 \t accuracy: 0.727 \t test accuracy: 0.748\n",
            "I: 30 \t accuracy: 0.752 \t test accuracy: 0.769\n",
            "I: 40 \t accuracy: 0.779 \t test accuracy: 0.783\n",
            "I: 50 \t accuracy: 0.809 \t test accuracy: 0.788\n",
            "I: 60 \t accuracy: 0.797 \t test accuracy: 0.794\n",
            "I: 70 \t accuracy: 0.826 \t test accuracy: 0.799\n",
            "I: 80 \t accuracy: 0.845 \t test accuracy: 0.809\n",
            "I: 90 \t accuracy: 0.864 \t test accuracy: 0.809\n",
            "I: 99 \t accuracy: 0.874 \t test accuracy: 0.804\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Tensor (object):\n",
        "\n",
        "    def __init__(self,data,\n",
        "                 autograd=False,\n",
        "                 creators=None,\n",
        "                 creation_op=None,\n",
        "                 id=None):\n",
        "\n",
        "        self.data = np.array(data)\n",
        "        self.autograd = autograd\n",
        "        self.grad = None\n",
        "        if(id is None):\n",
        "            self.id = np.random.randint(0,100000)\n",
        "        else:\n",
        "            self.id = id\n",
        "\n",
        "        self.creators = creators\n",
        "        self.creation_op = creation_op\n",
        "        self.children = {}\n",
        "\n",
        "        if(creators is not None):\n",
        "            for c in creators:\n",
        "                if(self.id not in c.children):\n",
        "                    c.children[self.id] = 1\n",
        "                else:\n",
        "                    c.children[self.id] += 1\n",
        "\n",
        "    def all_children_grads_accounted_for(self):\n",
        "        for id,cnt in self.children.items():\n",
        "            if(cnt != 0):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def backward(self,grad=None, grad_origin=None):\n",
        "        if(self.autograd):\n",
        "\n",
        "            if(grad is None):\n",
        "                grad = Tensor(np.ones_like(self.data))\n",
        "\n",
        "            if(grad_origin is not None):\n",
        "                if(self.children[grad_origin.id] == 0):\n",
        "                    raise Exception(\"cannot backprop more than once\")\n",
        "                else:\n",
        "                    self.children[grad_origin.id] -= 1\n",
        "\n",
        "            if(self.grad is None):\n",
        "                self.grad = grad\n",
        "            else:\n",
        "                self.grad += grad\n",
        "\n",
        "            # grads must not have grads of their own\n",
        "            assert grad.autograd == False\n",
        "\n",
        "            # only continue backpropping if there's something to\n",
        "            # backprop into and if all gradients (from children)\n",
        "            # are accounted for override waiting for children if\n",
        "            # \"backprop\" was called on this variable directly\n",
        "            if (self.creators is not None and\n",
        "               (self.all_children_grads_accounted_for() or\n",
        "                grad_origin is None)):\n",
        "\n",
        "                if (self.creation_op == \"add\"):\n",
        "                    self.creators[0].backward(self.grad, self)\n",
        "                    self.creators[1].backward(self.grad, self)\n",
        "\n",
        "                if (self.creation_op == \"sub\"):\n",
        "                    self.creators[0].backward(Tensor(self.grad.data), self)\n",
        "                    self.creators[1].backward(Tensor(self.grad.__neg__().data), self)\n",
        "\n",
        "                if (self.creation_op == \"mul\"):\n",
        "                    new = self.grad * self.creators[1]\n",
        "                    self.creators[0].backward(new , self)\n",
        "                    new = self.grad * self.creators[0]\n",
        "                    self.creators[1].backward(new, self)\n",
        "\n",
        "                if (self.creation_op == \"mm\"):\n",
        "                    c0 = self.creators[0]\n",
        "                    c1 = self.creators[1]\n",
        "                    new = self.grad.mm(c1.transpose())\n",
        "                    c0.backward(new)\n",
        "                    new = self.grad.transpose().mm(c0).transpose()\n",
        "                    c1.backward(new)\n",
        "\n",
        "                if (self.creation_op == \"transpose\"):\n",
        "                    self.creators[0].backward(self.grad.transpose())\n",
        "\n",
        "                if (\"sum\" in self.creation_op):\n",
        "                    dim = int(self.creation_op.split(\"_\")[1])\n",
        "                    self.creators[0].backward(self.grad.expand(dim,self.creators[0].data.shape[dim]))\n",
        "\n",
        "                if (\"expand\" in self.creation_op):\n",
        "                    dim = int(self.creation_op.split(\"_\")[1])\n",
        "                    self.creators[0].backward(self.grad.sum(dim))\n",
        "\n",
        "                if(self.creation_op == \"neg\"):\n",
        "                    self.creators[0].backward(self.grad.__neg__())\n",
        "\n",
        "                if (self.creation_op == \"sigmoid\"):\n",
        "                    ones = Tensor(np.ones_like(self.grad.data))\n",
        "                    self.creators[0].backward(self.grad * (self * (ones - self)))\n",
        "\n",
        "                if (self.creation_op == \"tanh\"):\n",
        "                    ones = Tensor(np.ones_like(self.grad.data))\n",
        "                    self.creators[0].backward(self.grad * (ones - (self * self)))\n",
        "\n",
        "                if (self.creation_op == \"index_select\"):\n",
        "                    new_grad = np.zeros_like(self.creators[0].data)\n",
        "                    indices_ = self.index_select_indices.data.flatten()\n",
        "                    grad_ = grad.data.reshape(len(indices_), -1)\n",
        "                    for i in range(len(indices_)):\n",
        "                        new_grad[indices_[i]] += grad_[i]\n",
        "                    self.creators[0].backward(Tensor(new_grad))\n",
        "\n",
        "                if (self.creation_op == \"cross_entropy\"):\n",
        "                    dx = self.softmax_output - self.target_dist\n",
        "                    self.creators[0].backward(Tensor(dx))\n",
        "\n",
        "    @property\n",
        "    def shape(self):\n",
        "        return self.data.shape\n",
        "\n",
        "    def __add__(self, other):\n",
        "        if (self.autograd and other.autograd):\n",
        "            return Tensor(self.data + other.data,\n",
        "                          autograd=True,\n",
        "                          creators=[self,other],\n",
        "                          creation_op=\"add\")\n",
        "        return Tensor(self.data + other.data)\n",
        "\n",
        "    def __neg__(self):\n",
        "        if (self.autograd):\n",
        "            return Tensor(self.data * -1,\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"neg\")\n",
        "        return Tensor(self.data * -1)\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        if (self.autograd and other.autograd):\n",
        "            return Tensor(self.data - other.data,\n",
        "                          autograd=True,\n",
        "                          creators=[self,other],\n",
        "                          creation_op=\"sub\")\n",
        "        return Tensor(self.data - other.data)\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        if (self.autograd and other.autograd):\n",
        "            return Tensor(self.data * other.data,\n",
        "                          autograd=True,\n",
        "                          creators=[self,other],\n",
        "                          creation_op=\"mul\")\n",
        "        return Tensor(self.data * other.data)\n",
        "\n",
        "    def sum(self, dim):\n",
        "        if (self.autograd):\n",
        "            return Tensor(self.data.sum(dim),\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"sum_\"+str(dim))\n",
        "        return Tensor(self.data.sum(dim))\n",
        "\n",
        "    def expand(self, dim,copies):\n",
        "\n",
        "        trans_cmd = list(range(0,len(self.data.shape)))\n",
        "        trans_cmd.insert(dim,len(self.data.shape))\n",
        "        new_data = self.data.repeat(copies).reshape(list(self.data.shape) + [copies]).transpose(trans_cmd)\n",
        "\n",
        "        if (self.autograd):\n",
        "            return Tensor(new_data,\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"expand_\"+str(dim))\n",
        "        return Tensor(new_data)\n",
        "\n",
        "    def transpose(self):\n",
        "        if (self.autograd):\n",
        "            return Tensor(self.data.transpose(),\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"transpose\")\n",
        "\n",
        "        return Tensor(self.data.transpose())\n",
        "\n",
        "    def mm(self, x):\n",
        "        if (self.autograd):\n",
        "            return Tensor(self.data.dot(x.data),\n",
        "                          autograd=True,\n",
        "                          creators=[self,x],\n",
        "                          creation_op=\"mm\")\n",
        "        return Tensor(self.data.dot(x.data))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.data.__repr__())\n",
        "\n",
        "    def __str__(self):\n",
        "        return str(self.data.__str__())\n",
        "\n",
        "    def sigmoid(self):\n",
        "        if (self.autograd):\n",
        "            return Tensor(1 / (1 + np.exp(-self.data)), autograd=True, creators=[self], creation_op = \"sigmoid\")\n",
        "        return Tensor(1 / (1 + np.exp(-self.data)))\n",
        "\n",
        "    def tanh(self):\n",
        "        if (self.autograd):\n",
        "            return Tensor(np.tanh(self.data), autograd=True, creators=[self], creation_op = \"tanh\")\n",
        "        return Tensor(np.tanh(self.data))\n",
        "\n",
        "    def index_select(self, indices):\n",
        "        if (self.autograd):\n",
        "            new = Tensor(self.data[indices.data], autograd=True, creators=[self], creation_op = \"index_select\")\n",
        "            new.index_select_indices = indices\n",
        "            return new\n",
        "        return Tensor(self.data[indices.data])\n",
        "\n",
        "    def cross_entropy(self, target_indices):\n",
        "        temp = np.exp(self.data)\n",
        "        softmax_output = temp / np.sum(temp, axis=len(self.data.shape)-1, keepdims=True)\n",
        "        target_dist = target.data\n",
        "        loss = -(np.log(softmax_output) * target_dist).sum(axis=1).mean()\n",
        "\n",
        "        if (self.autograd):\n",
        "            out = Tensor(loss, autograd=True, creators=[self], creation_op=\"cross_entropy\")\n",
        "            out.softmax_output = softmax_output\n",
        "            out.target_dist = target_dist\n",
        "            return out\n",
        "\n",
        "        return Tensor(loss)\n",
        "\n",
        "class SGD(object):\n",
        "    def __init__(self, parameters, alpha=0.1):\n",
        "        self.parameters = parameters\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def zero(self):\n",
        "        for p in self.parameters:\n",
        "            p.grad.data *= 0\n",
        "\n",
        "    def step(self, zero=True):\n",
        "        for p in self.parameters:\n",
        "            p.data -= p.grad.data * self.alpha\n",
        "\n",
        "            if (zero):\n",
        "                p.grad.data *= 0\n",
        "\n",
        "class Layer(object):\n",
        "    def __init__(self):\n",
        "        self.parameters = list()\n",
        "\n",
        "    def get_parameters(self):\n",
        "        return self.parameters\n",
        "\n",
        "class Linear(Layer):\n",
        "    def __init__(self, n_inputs, n_outputs):\n",
        "        super().__init__()\n",
        "        W = np.random.randn(n_inputs, n_outputs) * np.sqrt(2.0 / (n_inputs))\n",
        "        self.weight = Tensor(W, autograd=True)\n",
        "        self.bias = Tensor(np.zeros(n_outputs), autograd=True)\n",
        "\n",
        "        self.parameters.append(self.weight)\n",
        "        self.parameters.append(self.bias)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input.mm(self.weight) + self.bias.expand(0, len(input.data))\n",
        "\n",
        "class Sequential(Layer):\n",
        "    def __init__(self, layers=list(), training=True):\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.training = training\n",
        "\n",
        "    def add(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def forward(self, input):\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, Dropout):\n",
        "                layer.training = self.training\n",
        "            input = layer.forward(input)\n",
        "        return input\n",
        "\n",
        "    def train(self):\n",
        "        self.training = True\n",
        "\n",
        "    def eval(self):\n",
        "        self.training = False\n",
        "\n",
        "    def get_parameters(self):\n",
        "        params = list()\n",
        "        for l in self.layers:\n",
        "            params += l.get_parameters()\n",
        "        return params\n",
        "\n",
        "class Dropout(Layer):\n",
        "    def __init__(self, p=0.5):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Only apply dropout when training.\n",
        "        if self.training:\n",
        "            # Multiply by 1 / (1 - p) to balance out the extra sensitivity.\n",
        "            self.mask = np.random.binomial(1, 1-self.p, input.shape) / (1-self.p)\n",
        "            return input * Tensor(self.mask, autograd=input.autograd)\n",
        "        return input\n",
        "\n",
        "    def backward(self, grad):\n",
        "        return grad * self.mask\n",
        "\n",
        "\n",
        "class MSELoss(Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        return ((pred - target) * (pred - target)).sum(0)\n",
        "\n",
        "\n",
        "class CrossEntropyLoss(object):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return input.cross_entropy(target)\n",
        "\n",
        "class Tanh(Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input.tanh()\n",
        "\n",
        "class Sigmoid(Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input.sigmoid()\n",
        "\n",
        "class Relu(Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input.relu()\n",
        "\n",
        "\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train[0:1_000].reshape(1_000,28*28) / 255\n",
        "X_test = X_test[0:1_000].reshape(1_000,28*28) / 255\n",
        "y_train = y_train[0:1_000]\n",
        "y_test = y_test[0:1_000]\n",
        "\n",
        "# Onehot encoding\n",
        "y_train = np.eye(10)[y_train]\n",
        "y_test = np.eye(10)[y_test]\n",
        "\n",
        "# Hyperparameters\n",
        "alpha = 0.001\n",
        "epochs = 100\n",
        "batch_size = 100\n",
        "input_dim = 784\n",
        "hidden_size = 100\n",
        "output_dim = 10\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential([\n",
        "    Linear(input_dim,hidden_size),\n",
        "    Tanh(),\n",
        "    Dropout(p=0.5),\n",
        "    Linear(hidden_size, hidden_size),\n",
        "    Tanh(),\n",
        "    Dropout(p=0.5),\n",
        "    Linear(hidden_size, output_dim),\n",
        "    Sigmoid()\n",
        "])\n",
        "\n",
        "criterion = CrossEntropyLoss()\n",
        "optimizer = SGD(model.get_parameters(), alpha)\n",
        "\n",
        "# Training loop\n",
        "for j in range(epochs):\n",
        "    correct_cnt = 0\n",
        "    model.train()\n",
        "    for i in range(int(len(X_train) / batch_size)):\n",
        "        batch_start, batch_end = ((i * batch_size), ((i+1) * batch_size))\n",
        "        input = Tensor(X_train[batch_start:batch_end], autograd=True)\n",
        "        target = Tensor(y_train[batch_start:batch_end], autograd=True)\n",
        "\n",
        "        # Forward pass\n",
        "        prediction = model.forward(input)\n",
        "\n",
        "        loss = criterion.forward(prediction, target)\n",
        "\n",
        "        for k, p in enumerate(prediction.data):\n",
        "            pred_label = p\n",
        "            true_label = y_train[batch_start+k: batch_start+k+1]\n",
        "            correct_cnt += int(np.argmax(pred_label.data) == np.argmax(true_label))\n",
        "\n",
        "        # Back propgation\n",
        "        loss.backward()\n",
        "        # Update the weights0\n",
        "        optimizer.step()\n",
        "\n",
        "    training_accuracy = correct_cnt / float(len(y_train))\n",
        "\n",
        "    if (j % 10 == 0 or j == epochs - 1):\n",
        "        model.eval()\n",
        "        test_correct_cnt = 0\n",
        "        for i in range(int(len(X_test) / batch_size)):\n",
        "          batch_start, batch_end = ((i * batch_size), ((i+1) * batch_size))\n",
        "          input = Tensor(X_test[batch_start:batch_end], autograd=True)\n",
        "          target = Tensor(y_test[batch_start:batch_end], autograd=True)\n",
        "\n",
        "          # Forward pass\n",
        "          prediction = model.forward(input)\n",
        "\n",
        "          for k, p in enumerate(prediction.data):\n",
        "              pred_label = p\n",
        "              true_label = y_test[batch_start+k: batch_start+k+1]\n",
        "              test_correct_cnt += int(np.argmax(pred_label.data) == np.argmax(true_label))\n",
        "\n",
        "        test_accuracy = test_correct_cnt / float(len(y_test))\n",
        "        print(f\"I: {j} \\t accuracy: {training_accuracy} \\t test accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # $ L^2$ Regularization - Ridge regresssion\n",
        "\n",
        "The $L^2$ parameters norm penalty common known as **weight decay**. This regularization strategy drives the weights closer to the origin, by adding a regularozation term $\\Omega (\\theta) = \\frac{1}{2} || w ||^2_2$ to the objective function. In other academic communities, $L^2$ reguliarzation is also known as **ridge regression** or **Tikhonoz regularization**.\n",
        "\n",
        "Such a model has the total objective function\n",
        "\n",
        "$$\n",
        "  \\tilde{J} (w;X,y) = \\frac{\\alpha}{2} w^\\top w + J(w;X,y)\n",
        "$$\n",
        "\n",
        "with the corresponding parameter gradient\n",
        "\n",
        "$$\n",
        "  \\nabla_w \\tilde{j} (W;X,y) = \\alpha w + \\nabla_w J(w;X,y)\n",
        "$$\n",
        "\n",
        "To take a single gradient step to update the weights, we perform this update\n",
        "\n",
        "$$\n",
        "  w \\leftarrow w - \\epsilon(\\alpha w + \\nabla_w J(w;X,y))\n",
        "$$\n",
        "\n",
        "Written another way, the update is\n",
        "\n",
        "$$\n",
        "  w \\leftarrow (1 - \\epsilon \\alpha)w - \\epsilon \\nabla_w J(w;X,y)\n",
        "$$\n",
        "\n",
        "We can see that the addition of the weight decay term  has modified the learning rule to multiplicatively shrink the weight vector by a constant factor on each step, just before performing the usual gradient update. THis describes what happens in a single step\n",
        "\n",
        "We will further simplify analysis by making a quadratic approximation to the objective function in the neighborhood of the value of weights tat obtian minimal unregularized training cost $w^* = argmin_w J(w)$. If the objective function is truly quadratic, as in the case of fitting a linear regression model with mean equared error, then the approximation is perfect. The approximation $\\hat{J}$ is given by\n",
        "\n",
        "$$\n",
        "  \\hat{J}(\\theta) = J(w^*) + \\frac{1}{2}(w - w^*)^\\top H(w - w^*)\n",
        "$$\n",
        "\n",
        "where $H$ is the Hessian matrix of $J$ with respect to $w$ evaluated at $w^*$. There is no first-order term in the quadratic approximation, becuase $w^*$ is defined to be a minimum, where the gradient vanishes. Likewise, because $w^*$ is the location of a minimum of $J$, we can conclude $H$ is positive semidefinite.\n",
        "\n",
        "Remember: Hessian is the Jacobian of the gradients. And positive semidefinite means the eigenvalues are zero or positive.\n",
        "\n",
        "The minimum of $\\hat{J}$ occurs where its gradient\n",
        "\n",
        "$$\n",
        "  \\nabla_w \\hat{J} (w) = H (w - w^*)\n",
        "$$\n",
        "\n",
        "is equal to $0$.\n",
        "\n",
        "To studey the effect of weight decay, we modify the equation above by adding the weight decay gradient. We can now solve for the minimum of the regularized versio of $\\hat{J}$. We use the variable $\\tilde{w}$ to represent the location of the minimum.\n",
        "\n",
        "$$\n",
        "  \\alpha \\tilde{w} + H(\\tilde{w} - w^*) = 0 \\\\\n",
        "  (H + \\alpha I) \\tilde{w} = Hw^* \\\\\n",
        "  \\tilde{w} = (H + \\alpha I)^{-1} Hw^*\n",
        "$$\n",
        "\n",
        "As $alpha$ appproaches $0$, the regularized solution $\\tilde{w}$ approaches $w^*$. But what happens as $\\alpha$ grows. Becuase $H$ is real and symmetric, we can decompose it into a diagonal matrix $\\Lambda$ and an orthonormal basis of eigenvectors, $Q$, such that $H = Q\\Lambda Q^\\top$.\n",
        "\n",
        "Applying the decomposition, we obtain\n",
        "\n",
        "$$\n",
        "  \\tilde{w} = (Q\\Lambda Q^\\top + \\alpha I)^{-1} Q\\Lambda Q^\\top w^* \\\\\n",
        "  = [Q(\\Lambda + \\alpha I) Q^\\top]^{-1} Q\\Lambda Q^\\top w^* \\\\\n",
        "  = Q(\\Lambda + \\alpha I)^{-1} \\Lambda Q^\\top w^*\n",
        "$$\n",
        "\n",
        "We see that the effect of the weight decay is to recale $w^*$ along the axes defined by the eigenvectors of $H$. Specifically, the component $w^*$ that is aligned with the $i$th eigenvector of $J$ is recaled by a factor of $\\frac{\\lambda_i}{\\lambda_i + \\alpha}$"
      ],
      "metadata": {
        "id": "Yz1XZaEkKklM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For linear regression the cost function is the sum of squared errors:\n",
        "\n",
        "$$\n",
        "  (Xw - y)^\\top (Xw - y)\n",
        "$$\n",
        "\n",
        "When we add $L^2$ regularization, the objective function changes to\n",
        "\n",
        "$$\n",
        "  (Xw - y)^\\top (Xw - y) + \\frac{1}{2}\\alpha w^\\top w\n",
        "$$\n",
        "\n",
        "This changes the normal equations for the solution from\n",
        "\n",
        "$$\n",
        "  w = (X^\\top X)^{-1} X^\\top y\n",
        "$$\n",
        "\n",
        "to\n",
        "\n",
        "$$\n",
        "  w = (X^\\top X + \\alpha I)^{-1} X^\\top y\n",
        "$$\n",
        "\n",
        "The matrix $X^\\top X$ in the equation above is proportional to the covariance matrix $\\frac{1}{m} X^\\top X$. Using the $L^2$ regularization replaces this matrix with $(X^\\top X + \\alpha I)^{-1}$. The new matrix is the same as the original one, but with the addition of $\\alpha$ to the diagonal. The diagonal entires of this matrix correspond to the variance of each input feature. We can see that $L^2$ regularization cuases the learning algorithm to percieve the input $X$ as having higher variance, which makes it shrink the weights on features whose covariance with the output target is low compared to this added variance."
      ],
      "metadata": {
        "id": "w7PEVoHR0ern"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RidgeLoss(Layer):\n",
        "    def __init__(self, alpha=1.0):\n",
        "        super().__init__()\n",
        "        self.alpha = Tensor(alpha, autograd=True)  # Regularization strength\n",
        "\n",
        "    def forward(self, pred, target, model):\n",
        "        # Compute the Mean Squared Error (MSE)\n",
        "        mse_loss = ((pred - target)*(pred - target)).sum(0)\n",
        "\n",
        "        # Compute the Ridge (L2) regularization term\n",
        "        ridge_loss = Tensor(0.0, autograd=True)\n",
        "        for param in model.get_parameters():\n",
        "            ridge_loss += Tensor((param.data ** 2).sum(), autograd=True)\n",
        "\n",
        "        # Combine MSE loss and Ridge regularization\n",
        "        total_loss = mse_loss + self.alpha * ridge_loss\n",
        "        return total_loss\n",
        "\n",
        "# Hyperparameters\n",
        "input_dim = 784\n",
        "output_dim = 10\n",
        "hidden_size = 50\n",
        "alpha = 0.01\n",
        "epochs = 100\n",
        "batch_size = 100\n",
        "lambda_reg = 1\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential([\n",
        "    Linear(input_dim, hidden_size),\n",
        "    Tanh(),\n",
        "    Linear(hidden_size, output_dim),\n",
        "    Sigmoid()\n",
        "])\n",
        "\n",
        "criterion = RidgeLoss(lambda_reg)\n",
        "optimizer = SGD(model.get_parameters(), alpha)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    correct_cnt = 0\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        batch_X = X_train[i:i+batch_size]\n",
        "        batch_y = y_train[i:i+batch_size]\n",
        "\n",
        "        input = Tensor(batch_X, autograd=True)\n",
        "        target = Tensor(batch_y, autograd=True)\n",
        "\n",
        "        # Forward pass\n",
        "        prediction = model.forward(input)\n",
        "        loss = criterion.forward(prediction, target, model)\n",
        "        total_loss += loss.data\n",
        "\n",
        "        for i in range(len(prediction.data)):\n",
        "            pred_label = prediction.data[i]\n",
        "            true_label = batch_y[i]\n",
        "            correct_cnt += int(np.argmax(pred_label.data) == np.argmax(true_label))\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "    accuracy = correct_cnt / float(len(y_train))\n",
        "    avg_loss = total_loss / (len(X_train) / batch_size)\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Accuracy: {accuracy}, Average Loss: {avg_loss}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "X_test_tensor = Tensor(X_test, autograd=True)\n",
        "y_pred = model.forward(X_test_tensor)\n",
        "test_accuracy = 0\n",
        "for i in range(len(y_pred.data)):\n",
        "    pred_label = y_pred.data[i]\n",
        "    true_label = y_test [i]\n",
        "    test_accuracy += int(np.argmax(pred_label.data) == np.argmax(true_label))\n",
        "test_accuracy = test_accuracy / float(len(y_test))\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "mse = ((y_pred.data - y_test) ** 2).mean()\n",
        "print(f\"Test MSE: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Btj_Xl68wmT",
        "outputId": "943edf04-46b1-4a45-920f-385947a7f2d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Accuracy: 0.218, Average Loss: [151.14980994 151.82856124 152.87026549 152.32658156 153.29569342\n",
            " 153.71550238 150.40138061 152.9466566  152.21460277 153.98905984]\n",
            "Epoch 10, Accuracy: 0.92, Average Loss: [199.26083543 199.6837563  200.48314094 200.24990728 199.86259332\n",
            " 201.50202756 199.75383511 200.09991734 200.85029789 200.68123405]\n",
            "Epoch 20, Accuracy: 0.964, Average Loss: [237.09703836 237.49574915 237.78261246 237.60957519 237.43434781\n",
            " 238.15779056 237.34933208 237.49808163 237.80691848 237.94105403]\n",
            "Epoch 30, Accuracy: 0.979, Average Loss: [264.91860295 265.25474381 265.35436521 265.31848694 265.17820094\n",
            " 265.5597743  265.07975477 265.13401559 265.29853381 265.59751995]\n",
            "Epoch 40, Accuracy: 0.984, Average Loss: [286.20442692 286.52582521 286.49997669 286.56695953 286.38973139\n",
            " 286.69534539 286.34417183 286.33361676 286.4033552  286.75650289]\n",
            "Epoch 50, Accuracy: 0.985, Average Loss: [303.35812479 303.67111967 303.55752762 303.69041233 303.50361865\n",
            " 303.69803671 303.48432238 303.44345764 303.48008191 303.84881044]\n",
            "Epoch 60, Accuracy: 0.987, Average Loss: [317.09215547 317.39998668 317.25795262 317.3762779  317.20307625\n",
            " 317.35597473 317.21223971 317.15531976 317.17756081 317.55117727]\n",
            "Epoch 70, Accuracy: 0.989, Average Loss: [328.91836024 329.22308248 329.06636973 329.1395761  328.97085005\n",
            " 329.10101082 329.03388958 328.96601639 328.98400994 329.34803896]\n",
            "Epoch 80, Accuracy: 0.99, Average Loss: [339.04421404 339.34643402 339.18209587 339.22548553 339.08003298\n",
            " 339.19689748 339.15630366 339.08370401 339.09563158 339.42854425]\n",
            "Epoch 90, Accuracy: 0.99, Average Loss: [347.87750215 348.1782407  348.00852079 348.02945167 347.90436606\n",
            " 348.0160869  347.98708762 347.90921021 347.91888733 348.22700247]\n",
            "Test Accuracy: 0.854\n",
            "Test MSE: 0.02270070041393456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# $L^1$ Regularization - Lasso regression\n",
        "\n",
        "While $L^2$ weight decay is the most common form of weight decay, there are other ways to penalize the size of model parameters. Another option is to use the $L^1$ regularization, otherwise known as **lasso regression**.\n",
        "\n",
        "Formally, $L^1$ regularization on the model parameter $w$ is defined as\n",
        "\n",
        "$$\n",
        "  \\Omega(\\theta) = ||w||_1 = \\sum_i |w_i|\n",
        "$$\n",
        "\n",
        "that is, as the sum of absolute values of the individual parameters.\n",
        "\n",
        "As with $L^2$ weight decay, $L^1$ weight decay controls the strength of the regularization by scaling the penalty $\\Omega$ using a positive hyperparameter $\\alpha$. Thus, the regularized objective function $\\tilde{J} (w;X,y)$ is given by\n",
        "\n",
        "$$\n",
        "  \\tilde{J} (w;X,y) = \\alpha ||w||_1 + J(w;X,y)\n",
        "$$\n",
        "\n",
        "with the corresponding gradient\n",
        "\n",
        "$$\n",
        "  \\nabla_w \\tilde{J} (w;X,y) = \\alpha sign(w) + \\nabla_w J(X,y;w)\n",
        "$$\n",
        "\n",
        "where $sign(w)$ is simply the sign of $w$ applied element-wise.\n",
        "\n",
        "We can see that the regularization contribution to the gradient no longer scales linearly with each $w_i$; instead it is a constant factor with sign equal to $sign(w_i)$. One consequence of this form of gradient is that we will not necessarily see clean algebraic solutions to quadratic approximiations of $J(X,y;w)$ as we did for $L^2$ regularization.\n",
        "\n",
        "Our simple linear model has a quadratic cost function that we can represent via its Taylor series. Alternatively, we could imagine that this is a truncated Taylor series approximating the cost function of a more sophisticated model. The gradient in this setting is given by\n",
        "\n",
        "$$\n",
        "  \\nabla_w \\hat{J}(w) = H(w - w^*)\n",
        "$$\n",
        "\n",
        "where, again, $H$ is a Hessian matrix of $J$ with respect to $w$ evaluated at $w^*$\n",
        "\n",
        "Becuase the $L^1$ penalty does not admit clean algebraic expressions in the case of a fully general Hessian, we will also make the further simplifying assumption that the Hessian is diagonal, $H = diag([H_{1,1}, \\cdots, H_{n,n}])$ where $H_{i,i} > 0$. This assumption holds if the data for the linear regression problem has been preprocessed to remove all correlation between input features, which is accomplished using PCA.\n",
        "\n",
        "Our quadratic approximation of the $L^1$ regularizaed objective  function decomposes into a sum over the parameters.\n",
        "\n",
        "$$\n",
        "  \\hat{J}(w;X,y) - J(w^*;x,y) + \\sum_i [\\frac{1}{2} H_{i,i}(w_i - w_i^*)^2 + \\alpha |w_i|]\n",
        "$$\n",
        "\n",
        "The problem of minmizing the cost function has an analytical solution with the following form:\n",
        "\n",
        "$$\n",
        "  w_i = sign(w^*) max \\{ |w_i| - \\frac{\\alpha}{H_{i,i}}, 0\\}\n",
        "$$\n",
        "\n",
        "Consider the situation where $w_i^* > 0$ for all $i$. There are two possible outcomes:\n",
        "\n",
        "1. The case where $w_i^* \\le \\frac{\\alpha}{H_{i,i}}$. Here the optimal value of $w_i$ under the regularized objective is simply $w_i = 0$. This occurs because the contribution of $J(w;X,y)$ to the regularized objective $\\hat{J}(w;X,y)$ is overwhelmed - in direction $i$ - by the $L^1$ regularization, which puhses the value of $w_i$ to zero.\n",
        "2.  The case where $w_i^* > \\frac{\\alpha}{H_{i,i}}$. In this case, the regularization does not move the potimal value of $w_i$ to zero but instead just shifts it in the direction by a distance equal to $\\frac{\\alpha}{H_{i,i}}$\n",
        "\n",
        "A similar process happens when $w^*_i < 0$, but with the $L^1$ penalty making $w_i$ less negative by $\\frac{\\alpha}{H_{i,i}}$, or 0.\n",
        "\n",
        "In comparison to $L^2$ regularization, $L^1$ regularization results in a solution that is more **sparse**. Spartisity in this context refers to the fact that some parameters have an optimial value of zero. The sparsity of $L^1$ regularization is a qualitatively different behaviour than arises with $L^2$ regularization.\n",
        "\n",
        "This equation gave the solution for $\\tilde{w} for $L^2$ reguarlization:\n",
        "\n",
        "$$\n",
        "  \\tilde{w} = (H + \\alpha I)^{-1} Hw^*\n",
        "$$\n",
        "\n",
        "If we revisit that equation using the assumption of diagonal and positive semidefinite Hessian $H$ that we introduced for our analysis of $L^1$ regularization, we find that\n",
        "\n",
        "$$\n",
        "   \\tilde{w} = \\frac{H_{i,i}}{H_{i,i} + \\alpha} w_i^*\n",
        "$$\n",
        "\n",
        "If $w_i$ is nonzero, then $\\tilde{w}_i$ remains nonzero. This demonstrates that $L^2$ regularization does not cause the parameters to become spare, while $L^1$ regularization may do so for large enough $\\alpha$.\n",
        "\n",
        "$L^2$ regualirzation is equivalent to MAP Bayesian inference with a Gaussian prior on the weights. For $L^1$ regularization the penalty $ \\alpha \\Omega (w) = \\alpha \\sum_i |w_i| $ used to regularize the cost function is equivalent to the log-prior term that is maximized by MAP Bayesian inference when the prior is an isotropic Laplace distribution over $w \\in \\mathbb{R}^n$:\n",
        "\n",
        "$$\n",
        "  log p(w) = \\sum_i \\log Laplace(w_i;0,\\frac{1}{a}) \\\\\n",
        "  = -a ||w||_1 + n \\log \\alpha - n \\log 2\n",
        "$$\n",
        "\n",
        "From the point of view of learning via maximization with respect to $w$, we can ignore $\\log \\alpha - \\log 2$ terms because they do not depend on $w$.\n",
        "\n",
        "Remember: An even simpler version is the **isotropic** Gaussian distribution, whose covariance matrix is a scalar times the identity matrix."
      ],
      "metadata": {
        "id": "CNZAC9McGhl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LassoLoss(Layer):\n",
        "    def __init__(self, alpha=1.0):\n",
        "        super().__init__()\n",
        "        self.alpha = Tensor(alpha, autograd=True)  # Regularization strength\n",
        "\n",
        "    def forward(self, pred, target, model):\n",
        "        # Compute the Mean Squared Error (MSE)\n",
        "        mse_loss = ((pred - target) * (pred - target)).sum(0)\n",
        "\n",
        "        # Compute the Lasso (L1) regularization term\n",
        "        lasso_loss = Tensor(0.0, autograd=True)\n",
        "        for param in model.get_parameters():\n",
        "            lasso_loss += Tensor(np.abs(param.data).sum(), autograd=True)\n",
        "\n",
        "        # Combine MSE loss and Lasso regularization\n",
        "        total_loss = mse_loss + self.alpha * lasso_loss\n",
        "        return total_loss\n",
        "\n",
        "# Hyperparameters\n",
        "input_dim = 784\n",
        "output_dim = 10\n",
        "hidden_size = 50\n",
        "alpha = 0.01\n",
        "epochs = 100\n",
        "batch_size = 100\n",
        "lambda_reg = 1\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential([\n",
        "    Linear(input_dim, hidden_size),\n",
        "    Tanh(),\n",
        "    Linear(hidden_size, output_dim),\n",
        "    Sigmoid()\n",
        "])\n",
        "\n",
        "criterion = LassoLoss(lambda_reg)\n",
        "optimizer = SGD(model.get_parameters(), alpha)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    correct_cnt = 0\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        batch_X = X_train[i:i+batch_size]\n",
        "        batch_y = y_train[i:i+batch_size]\n",
        "\n",
        "        input = Tensor(batch_X, autograd=True)\n",
        "        target = Tensor(batch_y, autograd=True)\n",
        "\n",
        "        # Forward pass\n",
        "        prediction = model.forward(input)\n",
        "        loss = criterion.forward(prediction, target, model)\n",
        "        total_loss += loss.data\n",
        "\n",
        "        for i in range(len(prediction.data)):\n",
        "            pred_label = prediction.data[i]\n",
        "            true_label = batch_y[i]\n",
        "            correct_cnt += int(np.argmax(pred_label.data) == np.argmax(true_label))\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "    accuracy = correct_cnt / float(len(y_train))\n",
        "    avg_loss = total_loss / (len(X_train) / batch_size)\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Accuracy: {accuracy}, Average Loss: {avg_loss}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "X_test_tensor = Tensor(X_test, autograd=True)\n",
        "y_pred = model.forward(X_test_tensor)\n",
        "test_accuracy = 0\n",
        "for i in range(len(y_pred.data)):\n",
        "    pred_label = y_pred.data[i]\n",
        "    true_label = y_test [i]\n",
        "    test_accuracy += int(np.argmax(pred_label.data) == np.argmax(true_label))\n",
        "test_accuracy = test_accuracy / float(len(y_test))\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "mse = ((y_pred.data - y_test) ** 2).mean()\n",
        "print(f\"Test MSE: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NmOX-myGyKa",
        "outputId": "eb696d06-a19d-41b8-ef7e-36a1d53ac400"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Accuracy: 0.378, Average Loss: [1765.99193349 1765.81548299 1769.40022152 1767.45974641 1767.93693521\n",
            " 1769.36094945 1766.24101053 1769.00880046 1767.68171446 1769.05339325]\n",
            "Epoch 10, Accuracy: 0.935, Average Loss: [1957.43766685 1957.87984274 1958.38697974 1958.38323878 1958.15465007\n",
            " 1959.45018143 1957.78830902 1958.28507303 1958.68978519 1959.01481055]\n",
            "Epoch 20, Accuracy: 0.971, Average Loss: [2060.22790141 2060.57956897 2060.82455159 2060.78921787 2060.5959285\n",
            " 2061.0544305  2060.48003949 2060.64879881 2060.78191479 2061.25003752]\n",
            "Epoch 30, Accuracy: 0.983, Average Loss: [2130.47271141 2130.80384975 2130.89373795 2130.80893063 2130.75458628\n",
            " 2130.97104764 2130.62993237 2130.68178995 2130.76553174 2131.31777736]\n",
            "Epoch 40, Accuracy: 0.983, Average Loss: [2180.11926796 2180.43863561 2180.43619765 2180.38765883 2180.35372232\n",
            " 2180.46536125 2180.17689559 2180.23652105 2180.32655896 2180.77699571]\n",
            "Epoch 50, Accuracy: 0.986, Average Loss: [2217.07013642 2217.38325211 2217.33605881 2217.31232965 2217.24415294\n",
            " 2217.29382722 2217.10277621 2217.14473476 2217.24081019 2217.634185  ]\n",
            "Epoch 60, Accuracy: 0.987, Average Loss: [2245.70877334 2246.01709672 2245.90623863 2245.93664222 2245.82949866\n",
            " 2245.88898697 2245.729023   2245.76211413 2245.8614359  2246.19662847]\n",
            "Epoch 70, Accuracy: 0.988, Average Loss: [2269.26343117 2269.57036747 2269.41004618 2269.48367543 2269.3219839\n",
            " 2269.42102834 2269.27775152 2269.30443681 2269.40319326 2269.72505298]\n",
            "Epoch 80, Accuracy: 0.988, Average Loss: [2288.3668969  2288.67249101 2288.50059938 2288.58249482 2288.40382764\n",
            " 2288.51091014 2288.37784879 2288.3989737  2288.49697687 2288.8128778 ]\n",
            "Epoch 90, Accuracy: 0.988, Average Loss: [2304.36890354 2304.67365501 2304.49506637 2304.58145422 2304.39578951\n",
            " 2304.50425248 2304.37767074 2304.39495233 2304.49047403 2304.8046969 ]\n",
            "Test Accuracy: 0.859\n",
            "Test MSE: 0.022023452506961166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Norm Penalties as Constrained Optimization\n",
        "\n",
        "Consider the cost function regularized by a parameter norm penatly:\n",
        "\n",
        "$$\n",
        "  \\hat{J} (\\theta,X,y) = J(\\theta;X,y) + \\alpha \\Omega (\\theta)\n",
        "$$\n",
        "\n",
        "If we wanted to constrain $\\Omega(\\theta)$ to be less than some constant $k$, we could construct a generalized Lagrange function\n",
        "\n",
        "$$\n",
        "  \\mathcal{L} (\\theta, \\alpha; X, y) = J(\\theta;X,y) + \\alpha(\\Omega(\\theta) - k)\n",
        "$$\n",
        "\n",
        "The solution to the constrained problem is given by\n",
        "\n",
        "$$\n",
        "  \\theta^* = argmin_\\theta max_{a,a \\ge 0} \\mathcal{L}(\\theta,\\alpha)\n",
        "$$\n",
        "\n",
        "To gain some insight into the effect of this constraint, we can fix $\\alpha^*$ and view the problem as just a function of $\\theta$:\n",
        "\n",
        "$$\n",
        "  \\theta^* = arg min_\\theta \\mathcal{L}(\\theta,\\alpha^*) = arg min_\\theta J(\\theta;X,y) + \\alpha^* \\Omega(\\theta)\n",
        "$$\n",
        "\n",
        "This is exactly the same regularized training problem of minimizing $\\tilde{J}$. We can thus think of a parameter norm penalty as imposing a constraint on the weights. If $\\Omega$ is the $L^2$ norm, then the weights are constrained to lie in an $L^2$ ball. If $\\Omega$ is the $L^1$ norm, the weights are constrained to lie in a region of limited $L^1$ norm.\n",
        "\n",
        "Sometimes we may wish to use explicit constrains rather than penalties. We can modify algorithms such as stochastic gradient descent to take a step downhill on $J(\\theta)$ then project $\\theta$ back to the nearest point that satisfies $\\Omega(\\theta) < k$.\n",
        "\n",
        "(Hinton (2012) recoomend a strategy intorduced by (Srebo and Shraibman 2005): constraining the norm of each column of the weight matrix of a neural network layer, rather than constraining the Frobenious nrom of the entire weight matrix. Constraining the norm of each column seperately prevents any one hidden unit from having very large weights. If we converted with constraint into a penalty in a Lagrange function, it would be similar to $L^2$ weight decay but with a seperate KKT multiplier for the weights of each hidden unit. Each of thse KKT mutlipliers would be dynamically updated seperately to make each hidden unit obey the constraint. In practise, column norm limitation is always implmeneted as an explicit constraint with reprojection."
      ],
      "metadata": {
        "id": "u9Q5dASkpQUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regularization and Under-Constrained Problems\n",
        "\n",
        "In some cases, regularization is necessary for machine learning problems to be properly defined. Many linear models in machine learning, including linear regression and PCA, depend on inverting a matrix $X^top X$. This is not possible when $X^\\top X$ is singular. The matrix can be singular whenver the data-generating distribution turly has no variance in some direction, or when no variance is observed in some direction because there are fewer examples (rows of $X$) than input features (columns of $X$). In this case many forms of regularization correspond to inverting $X^top X + \\alpha I$ instead. This regularized matrix is guaranteed to be invertible.\n",
        "\n",
        "Linear problems have closed form solutions when the relevant matrix is inveritble. It is also possible for a problem with no closed form solution to be underdetermined. An example is logistic regression applied to a problem where the classes are linearly separable. If a weight vector $w$ is able to achieve perfect classification, then $2w$ will also achieve perfect classification and hihger likelihood. An iterative optmization procuded like stochastic gradient descent will continiously increase the magnitude of $w$ and, in theory, will never hault. In practise, a numerical implementation of gradient descent will eventually reach sufficiently large weights to cause numerical overflow, at which point its behaviour will depend on how the programmer has decided to handle values that are not real numbers.\n",
        "\n",
        "Most forms of regularization are able to guaranteee convergence of iterative methods applied to undetermined problems. For example, weight decay will cuase gradient descent to quit increasing the magnitude of the weights when the slope of the likelihood is equal to the weight decay coefficient.\n",
        "\n",
        "Recall that one definition of the psuedoinverse $X^+$ of matrix $X$ is\n",
        "\n",
        "$$\n",
        "   A^+ = \\lim_{\\alpha \\to 0} (X^T X + \\alpha I)^{-1} X^T\n",
        "$$\n",
        "\n",
        "We can now recognize this equation as performing linear regression with weight decay. Specifically, the equation above is the limit of\n",
        "\n",
        "$$\n",
        "  w = (X^TX + \\alpha I) X^\\top y\n",
        "$$\n",
        "\n",
        "as the regularization coefficient shrinks to zero. We can thus interpret the pseudoinverse as stabilizing underdetermined problems using regularization."
      ],
      "metadata": {
        "id": "f5lS3Z7kzaoV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Augmentation\n",
        "\n",
        "The best way to make a machine learning model generalize better is to train it on more data. Of course, in practise, the amount of data we have is limited. One way to get around this problem is to create fake data and add it to the training set. For some machine learning tasks it is reasonably straighforward to create new fake data.\n",
        "\n",
        "Data augmentation has been a particularly effective technique for a specific classification problem: object recognition. Images are high dimensional and include an enourmous range of factors of varaition, many of which can easily be simulated. Operations like translating the training images a few pixels in each direction can often greatly improve generalization, even if the model has been designed to be partially translation invariant by using colution and poolting techniques. MAny other operations, such as rotating the image or scaling the image, have also provded quite effective.\n",
        "\n",
        "Injecting noise in the input to a neural network (Sietsma & Dow 1991) can also be seen as a form of data augmentation.\n",
        "\n",
        "Dropout (Srivastava 2014) can be seen as a process of creating new inputs by _multiplying_ by noise."
      ],
      "metadata": {
        "id": "HX1sh0Gu2nOI"
      }
    }
  ]
}