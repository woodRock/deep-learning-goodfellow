{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNwKFccTmJ368eGJ6n/vmTs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woodRock/deep-learning-goodfellow/blob/main/chapter_7_regularization_for_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 7 | Regularization for Deep Learning\n",
        "\n",
        "We defined regularization as \"any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error\"."
      ],
      "metadata": {
        "id": "oHF0W8NFHiVm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_THe7whOHBvn",
        "outputId": "046e95fb-7792-4cd5-e188-deafc089bbbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I: 0 \t accuracy: 0.123 \t test accuracy: 0.231\n",
            "I: 10 \t accuracy: 0.625 \t test accuracy: 0.705\n",
            "I: 20 \t accuracy: 0.727 \t test accuracy: 0.748\n",
            "I: 30 \t accuracy: 0.752 \t test accuracy: 0.769\n",
            "I: 40 \t accuracy: 0.779 \t test accuracy: 0.783\n",
            "I: 50 \t accuracy: 0.809 \t test accuracy: 0.788\n",
            "I: 60 \t accuracy: 0.797 \t test accuracy: 0.794\n",
            "I: 70 \t accuracy: 0.826 \t test accuracy: 0.799\n",
            "I: 80 \t accuracy: 0.845 \t test accuracy: 0.809\n",
            "I: 90 \t accuracy: 0.864 \t test accuracy: 0.809\n",
            "I: 99 \t accuracy: 0.874 \t test accuracy: 0.804\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Tensor (object):\n",
        "\n",
        "    def __init__(self,data,\n",
        "                 autograd=False,\n",
        "                 creators=None,\n",
        "                 creation_op=None,\n",
        "                 id=None):\n",
        "\n",
        "        self.data = np.array(data)\n",
        "        self.autograd = autograd\n",
        "        self.grad = None\n",
        "        if(id is None):\n",
        "            self.id = np.random.randint(0,100000)\n",
        "        else:\n",
        "            self.id = id\n",
        "\n",
        "        self.creators = creators\n",
        "        self.creation_op = creation_op\n",
        "        self.children = {}\n",
        "\n",
        "        if(creators is not None):\n",
        "            for c in creators:\n",
        "                if(self.id not in c.children):\n",
        "                    c.children[self.id] = 1\n",
        "                else:\n",
        "                    c.children[self.id] += 1\n",
        "\n",
        "    def all_children_grads_accounted_for(self):\n",
        "        for id,cnt in self.children.items():\n",
        "            if(cnt != 0):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    def backward(self,grad=None, grad_origin=None):\n",
        "        if(self.autograd):\n",
        "\n",
        "            if(grad is None):\n",
        "                grad = Tensor(np.ones_like(self.data))\n",
        "\n",
        "            if(grad_origin is not None):\n",
        "                if(self.children[grad_origin.id] == 0):\n",
        "                    raise Exception(\"cannot backprop more than once\")\n",
        "                else:\n",
        "                    self.children[grad_origin.id] -= 1\n",
        "\n",
        "            if(self.grad is None):\n",
        "                self.grad = grad\n",
        "            else:\n",
        "                self.grad += grad\n",
        "\n",
        "            # grads must not have grads of their own\n",
        "            assert grad.autograd == False\n",
        "\n",
        "            # only continue backpropping if there's something to\n",
        "            # backprop into and if all gradients (from children)\n",
        "            # are accounted for override waiting for children if\n",
        "            # \"backprop\" was called on this variable directly\n",
        "            if (self.creators is not None and\n",
        "               (self.all_children_grads_accounted_for() or\n",
        "                grad_origin is None)):\n",
        "\n",
        "                if (self.creation_op == \"add\"):\n",
        "                    self.creators[0].backward(self.grad, self)\n",
        "                    self.creators[1].backward(self.grad, self)\n",
        "\n",
        "                if (self.creation_op == \"sub\"):\n",
        "                    self.creators[0].backward(Tensor(self.grad.data), self)\n",
        "                    self.creators[1].backward(Tensor(self.grad.__neg__().data), self)\n",
        "\n",
        "                if (self.creation_op == \"mul\"):\n",
        "                    new = self.grad * self.creators[1]\n",
        "                    self.creators[0].backward(new , self)\n",
        "                    new = self.grad * self.creators[0]\n",
        "                    self.creators[1].backward(new, self)\n",
        "\n",
        "                if (self.creation_op == \"mm\"):\n",
        "                    c0 = self.creators[0]\n",
        "                    c1 = self.creators[1]\n",
        "                    new = self.grad.mm(c1.transpose())\n",
        "                    c0.backward(new)\n",
        "                    new = self.grad.transpose().mm(c0).transpose()\n",
        "                    c1.backward(new)\n",
        "\n",
        "                if (self.creation_op == \"transpose\"):\n",
        "                    self.creators[0].backward(self.grad.transpose())\n",
        "\n",
        "                if (\"sum\" in self.creation_op):\n",
        "                    dim = int(self.creation_op.split(\"_\")[1])\n",
        "                    self.creators[0].backward(self.grad.expand(dim,self.creators[0].data.shape[dim]))\n",
        "\n",
        "                if (\"expand\" in self.creation_op):\n",
        "                    dim = int(self.creation_op.split(\"_\")[1])\n",
        "                    self.creators[0].backward(self.grad.sum(dim))\n",
        "\n",
        "                if(self.creation_op == \"neg\"):\n",
        "                    self.creators[0].backward(self.grad.__neg__())\n",
        "\n",
        "                if (self.creation_op == \"sigmoid\"):\n",
        "                    ones = Tensor(np.ones_like(self.grad.data))\n",
        "                    self.creators[0].backward(self.grad * (self * (ones - self)))\n",
        "\n",
        "                if (self.creation_op == \"tanh\"):\n",
        "                    ones = Tensor(np.ones_like(self.grad.data))\n",
        "                    self.creators[0].backward(self.grad * (ones - (self * self)))\n",
        "\n",
        "                if (self.creation_op == \"index_select\"):\n",
        "                    new_grad = np.zeros_like(self.creators[0].data)\n",
        "                    indices_ = self.index_select_indices.data.flatten()\n",
        "                    grad_ = grad.data.reshape(len(indices_), -1)\n",
        "                    for i in range(len(indices_)):\n",
        "                        new_grad[indices_[i]] += grad_[i]\n",
        "                    self.creators[0].backward(Tensor(new_grad))\n",
        "\n",
        "                if (self.creation_op == \"cross_entropy\"):\n",
        "                    dx = self.softmax_output - self.target_dist\n",
        "                    self.creators[0].backward(Tensor(dx))\n",
        "\n",
        "    @property\n",
        "    def shape(self):\n",
        "        return self.data.shape\n",
        "\n",
        "    def __add__(self, other):\n",
        "        if (self.autograd and other.autograd):\n",
        "            return Tensor(self.data + other.data,\n",
        "                          autograd=True,\n",
        "                          creators=[self,other],\n",
        "                          creation_op=\"add\")\n",
        "        return Tensor(self.data + other.data)\n",
        "\n",
        "    def __neg__(self):\n",
        "        if (self.autograd):\n",
        "            return Tensor(self.data * -1,\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"neg\")\n",
        "        return Tensor(self.data * -1)\n",
        "\n",
        "    def __sub__(self, other):\n",
        "        if (self.autograd and other.autograd):\n",
        "            return Tensor(self.data - other.data,\n",
        "                          autograd=True,\n",
        "                          creators=[self,other],\n",
        "                          creation_op=\"sub\")\n",
        "        return Tensor(self.data - other.data)\n",
        "\n",
        "    def __mul__(self, other):\n",
        "        if (self.autograd and other.autograd):\n",
        "            return Tensor(self.data * other.data,\n",
        "                          autograd=True,\n",
        "                          creators=[self,other],\n",
        "                          creation_op=\"mul\")\n",
        "        return Tensor(self.data * other.data)\n",
        "\n",
        "    def sum(self, dim):\n",
        "        if (self.autograd):\n",
        "            return Tensor(self.data.sum(dim),\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"sum_\"+str(dim))\n",
        "        return Tensor(self.data.sum(dim))\n",
        "\n",
        "    def expand(self, dim,copies):\n",
        "\n",
        "        trans_cmd = list(range(0,len(self.data.shape)))\n",
        "        trans_cmd.insert(dim,len(self.data.shape))\n",
        "        new_data = self.data.repeat(copies).reshape(list(self.data.shape) + [copies]).transpose(trans_cmd)\n",
        "\n",
        "        if (self.autograd):\n",
        "            return Tensor(new_data,\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"expand_\"+str(dim))\n",
        "        return Tensor(new_data)\n",
        "\n",
        "    def transpose(self):\n",
        "        if (self.autograd):\n",
        "            return Tensor(self.data.transpose(),\n",
        "                          autograd=True,\n",
        "                          creators=[self],\n",
        "                          creation_op=\"transpose\")\n",
        "\n",
        "        return Tensor(self.data.transpose())\n",
        "\n",
        "    def mm(self, x):\n",
        "        if (self.autograd):\n",
        "            return Tensor(self.data.dot(x.data),\n",
        "                          autograd=True,\n",
        "                          creators=[self,x],\n",
        "                          creation_op=\"mm\")\n",
        "        return Tensor(self.data.dot(x.data))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.data.__repr__())\n",
        "\n",
        "    def __str__(self):\n",
        "        return str(self.data.__str__())\n",
        "\n",
        "    def sigmoid(self):\n",
        "        if (self.autograd):\n",
        "            return Tensor(1 / (1 + np.exp(-self.data)), autograd=True, creators=[self], creation_op = \"sigmoid\")\n",
        "        return Tensor(1 / (1 + np.exp(-self.data)))\n",
        "\n",
        "    def tanh(self):\n",
        "        if (self.autograd):\n",
        "            return Tensor(np.tanh(self.data), autograd=True, creators=[self], creation_op = \"tanh\")\n",
        "        return Tensor(np.tanh(self.data))\n",
        "\n",
        "    def index_select(self, indices):\n",
        "        if (self.autograd):\n",
        "            new = Tensor(self.data[indices.data], autograd=True, creators=[self], creation_op = \"index_select\")\n",
        "            new.index_select_indices = indices\n",
        "            return new\n",
        "        return Tensor(self.data[indices.data])\n",
        "\n",
        "    def cross_entropy(self, target_indices):\n",
        "        temp = np.exp(self.data)\n",
        "        softmax_output = temp / np.sum(temp, axis=len(self.data.shape)-1, keepdims=True)\n",
        "        target_dist = target.data\n",
        "        loss = -(np.log(softmax_output) * target_dist).sum(axis=1).mean()\n",
        "\n",
        "        if (self.autograd):\n",
        "            out = Tensor(loss, autograd=True, creators=[self], creation_op=\"cross_entropy\")\n",
        "            out.softmax_output = softmax_output\n",
        "            out.target_dist = target_dist\n",
        "            return out\n",
        "\n",
        "        return Tensor(loss)\n",
        "\n",
        "class SGD(object):\n",
        "    def __init__(self, parameters, alpha=0.1):\n",
        "        self.parameters = parameters\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def zero(self):\n",
        "        for p in self.parameters:\n",
        "            p.grad.data *= 0\n",
        "\n",
        "    def step(self, zero=True):\n",
        "        for p in self.parameters:\n",
        "            p.data -= p.grad.data * self.alpha\n",
        "\n",
        "            if (zero):\n",
        "                p.grad.data *= 0\n",
        "\n",
        "class Layer(object):\n",
        "    def __init__(self):\n",
        "        self.parameters = list()\n",
        "\n",
        "    def get_parameters(self):\n",
        "        return self.parameters\n",
        "\n",
        "class Linear(Layer):\n",
        "    def __init__(self, n_inputs, n_outputs):\n",
        "        super().__init__()\n",
        "        W = np.random.randn(n_inputs, n_outputs) * np.sqrt(2.0 / (n_inputs))\n",
        "        self.weight = Tensor(W, autograd=True)\n",
        "        self.bias = Tensor(np.zeros(n_outputs), autograd=True)\n",
        "\n",
        "        self.parameters.append(self.weight)\n",
        "        self.parameters.append(self.bias)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input.mm(self.weight) + self.bias.expand(0, len(input.data))\n",
        "\n",
        "class Sequential(Layer):\n",
        "    def __init__(self, layers=list(), training=True):\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.training = training\n",
        "\n",
        "    def add(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def forward(self, input):\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, Dropout):\n",
        "                layer.training = self.training\n",
        "            input = layer.forward(input)\n",
        "        return input\n",
        "\n",
        "    def train(self):\n",
        "        self.training = True\n",
        "\n",
        "    def eval(self):\n",
        "        self.training = False\n",
        "\n",
        "    def get_parameters(self):\n",
        "        params = list()\n",
        "        for l in self.layers:\n",
        "            params += l.get_parameters()\n",
        "        return params\n",
        "\n",
        "class Dropout(Layer):\n",
        "    def __init__(self, p=0.5):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Only apply dropout when training.\n",
        "        if self.training:\n",
        "            # Multiply by 1 / (1 - p) to balance out the extra sensitivity.\n",
        "            self.mask = np.random.binomial(1, 1-self.p, input.shape) / (1-self.p)\n",
        "            return input * Tensor(self.mask, autograd=input.autograd)\n",
        "        return input\n",
        "\n",
        "    def backward(self, grad):\n",
        "        return grad * self.mask\n",
        "\n",
        "\n",
        "class MSELoss(Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        return ((pred - target) * (pred - target)).sum(0)\n",
        "\n",
        "\n",
        "class CrossEntropyLoss(object):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return input.cross_entropy(target)\n",
        "\n",
        "class Tanh(Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input.tanh()\n",
        "\n",
        "class Sigmoid(Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input.sigmoid()\n",
        "\n",
        "class Relu(Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return input.relu()\n",
        "\n",
        "\n",
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train[0:1_000].reshape(1_000,28*28) / 255\n",
        "X_test = X_test[0:1_000].reshape(1_000,28*28) / 255\n",
        "y_train = y_train[0:1_000]\n",
        "y_test = y_test[0:1_000]\n",
        "\n",
        "# Onehot encoding\n",
        "y_train = np.eye(10)[y_train]\n",
        "y_test = np.eye(10)[y_test]\n",
        "\n",
        "# Hyperparameters\n",
        "alpha = 0.001\n",
        "epochs = 100\n",
        "batch_size = 100\n",
        "input_dim = 784\n",
        "hidden_size = 100\n",
        "output_dim = 10\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential([\n",
        "    Linear(input_dim,hidden_size),\n",
        "    Tanh(),\n",
        "    Dropout(p=0.5),\n",
        "    Linear(hidden_size, hidden_size),\n",
        "    Tanh(),\n",
        "    Dropout(p=0.5),\n",
        "    Linear(hidden_size, output_dim),\n",
        "    Sigmoid()\n",
        "])\n",
        "\n",
        "criterion = CrossEntropyLoss()\n",
        "optimizer = SGD(model.get_parameters(), alpha)\n",
        "\n",
        "# Training loop\n",
        "for j in range(epochs):\n",
        "    correct_cnt = 0\n",
        "    model.train()\n",
        "    for i in range(int(len(X_train) / batch_size)):\n",
        "        batch_start, batch_end = ((i * batch_size), ((i+1) * batch_size))\n",
        "        input = Tensor(X_train[batch_start:batch_end], autograd=True)\n",
        "        target = Tensor(y_train[batch_start:batch_end], autograd=True)\n",
        "\n",
        "        # Forward pass\n",
        "        prediction = model.forward(input)\n",
        "\n",
        "        loss = criterion.forward(prediction, target)\n",
        "\n",
        "        for k, p in enumerate(prediction.data):\n",
        "            pred_label = p\n",
        "            true_label = y_train[batch_start+k: batch_start+k+1]\n",
        "            correct_cnt += int(np.argmax(pred_label.data) == np.argmax(true_label))\n",
        "\n",
        "        # Back propgation\n",
        "        loss.backward()\n",
        "        # Update the weights0\n",
        "        optimizer.step()\n",
        "\n",
        "    training_accuracy = correct_cnt / float(len(y_train))\n",
        "\n",
        "    if (j % 10 == 0 or j == epochs - 1):\n",
        "        model.eval()\n",
        "        test_correct_cnt = 0\n",
        "        for i in range(int(len(X_test) / batch_size)):\n",
        "          batch_start, batch_end = ((i * batch_size), ((i+1) * batch_size))\n",
        "          input = Tensor(X_test[batch_start:batch_end], autograd=True)\n",
        "          target = Tensor(y_test[batch_start:batch_end], autograd=True)\n",
        "\n",
        "          # Forward pass\n",
        "          prediction = model.forward(input)\n",
        "\n",
        "          for k, p in enumerate(prediction.data):\n",
        "              pred_label = p\n",
        "              true_label = y_test[batch_start+k: batch_start+k+1]\n",
        "              test_correct_cnt += int(np.argmax(pred_label.data) == np.argmax(true_label))\n",
        "\n",
        "        test_accuracy = test_correct_cnt / float(len(y_test))\n",
        "        print(f\"I: {j} \\t accuracy: {training_accuracy} \\t test accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # $ L^2$ Regularization - Ridge regresssion\n",
        "\n",
        "The $L^2$ parameters norm penalty common known as **weight decay**. This regularization strategy drives the weights closer to the origin, by adding a regularozation term $\\Omega (\\theta) = \\frac{1}{2} || w ||^2_2$ to the objective function. In other academic communities, $L^2$ reguliarzation is also known as **ridge regression** or **Tikhonoz regularization**.\n",
        "\n",
        "Such a model has the total objective function\n",
        "\n",
        "$$\n",
        "  \\tilde{J} (w;X,y) = \\frac{\\alpha}{2} w^\\top w + J(w;X,y)\n",
        "$$\n",
        "\n",
        "with the corresponding parameter gradient\n",
        "\n",
        "$$\n",
        "  \\nabla_w \\tilde{j} (W;X,y) = \\alpha w + \\nabla_w J(w;X,y)\n",
        "$$\n",
        "\n",
        "To take a single gradient step to update the weights, we perform this update\n",
        "\n",
        "$$\n",
        "  w \\leftarrow w - \\epsilon(\\alpha w + \\nabla_w J(w;X,y))\n",
        "$$\n",
        "\n",
        "Written another way, the update is\n",
        "\n",
        "$$\n",
        "  w \\leftarrow (1 - \\epsilon \\alpha)w - \\epsilon \\nabla_w J(w;X,y)\n",
        "$$\n",
        "\n",
        "We can see that the addition of the weight decay term  has modified the learning rule to multiplicatively shrink the weight vector by a constant factor on each step, just before performing the usual gradient update. THis describes what happens in a single step\n",
        "\n",
        "We will further simplify analysis by making a quadratic approximation to the objective function in the neighborhood of the value of weights tat obtian minimal unregularized training cost $w^* = argmin_w J(w)$. If the objective function is truly quadratic, as in the case of fitting a linear regression model with mean equared error, then the approximation is perfect. The approximation $\\hat{J}$ is given by\n",
        "\n",
        "$$\n",
        "  \\hat{J}(\\theta) = J(w^*) + \\frac{1}{2}(w - w^*)^\\top H(w - w^*)\n",
        "$$\n",
        "\n",
        "where $H$ is the Hessian matrix of $J$ with respect to $w$ evaluated at $w^*$. There is no first-order term in the quadratic approximation, becuase $w^*$ is defined to be a minimum, where the gradient vanishes. Likewise, because $w^*$ is the location of a minimum of $J$, we can conclude $H$ is positive semidefinite.\n",
        "\n",
        "Remember: Hessian is the Jacobian of the gradients. And positive semidefinite means the eigenvalues are zero or positive.\n",
        "\n",
        "The minimum of $\\hat{J}$ occurs where its gradient\n",
        "\n",
        "$$\n",
        "  \\nabla_w \\hat{J} (w) = H (w - w^*)\n",
        "$$\n",
        "\n",
        "is equal to $0$.\n",
        "\n",
        "To studey the effect of weight decay, we modify the equation above by adding the weight decay gradient. We can now solve for the minimum of the regularized versio of $\\hat{J}$. We use the variable $\\tilde{w}$ to represent the location of the minimum.\n",
        "\n",
        "$$\n",
        "  \\alpha \\tilde{w} + H(\\tilde{w} - w^*) = 0 \\\\\n",
        "  (H + \\alpha I) \\tilde{w} = Hw^* \\\\\n",
        "  \\tilde{w} = (H + \\alpha I)^{-1} Hw^*\n",
        "$$\n",
        "\n",
        "As $alpha$ appproaches $0$, the regularized solution $\\tilde{w}$ approaches $w^*$. But what happens as $\\alpha$ grows. Becuase $H$ is real and symmetric, we can decompose it into a diagonal matrix $\\Lambda$ and an orthonormal basis of eigenvectors, $Q$, such that $H = Q\\Lambda Q^\\top$.\n",
        "\n",
        "Applying the decomposition, we obtain\n",
        "\n",
        "$$\n",
        "  \\tilde{w} = (Q\\Lambda Q^\\top + \\alpha I)^{-1} Q\\Lambda Q^\\top w^* \\\\\n",
        "  = [Q(\\Lambda + \\alpha I) Q^\\top]^{-1} Q\\Lambda Q^\\top w^* \\\\\n",
        "  = Q(\\Lambda + \\alpha I)^{-1} \\Lambda Q^\\top w^*\n",
        "$$\n",
        "\n",
        "We see that the effect of the weight decay is to recale $w^*$ along the axes defined by the eigenvectors of $H$. Specifically, the component $w^*$ that is aligned with the $i$th eigenvector of $J$ is recaled by a factor of $\\frac{\\lambda_i}{\\lambda_i + \\alpha}$"
      ],
      "metadata": {
        "id": "Yz1XZaEkKklM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For linear regression the cost function is the sum of squared errors:\n",
        "\n",
        "$$\n",
        "  (Xw - y)^\\top (Xw - y)\n",
        "$$\n",
        "\n",
        "When we add $L^2$ regularization, the objective function changes to\n",
        "\n",
        "$$\n",
        "  (Xw - y)^\\top (Xw - y) + \\frac{1}{2}\\alpha w^\\top w\n",
        "$$\n",
        "\n",
        "This changes the normal equations for the solution from\n",
        "\n",
        "$$\n",
        "  w = (X^\\top X)^{-1} X^\\top y\n",
        "$$\n",
        "\n",
        "to\n",
        "\n",
        "$$\n",
        "  w = (X^\\top X + \\alpha I)^{-1} X^\\top y\n",
        "$$\n",
        "\n",
        "The matrix $X^\\top X$ in the equation above is proportional to the covariance matrix $\\frac{1}{m} X^\\top X$. Using the $L^2$ regularization replaces this matrix with $(X^\\top X + \\alpha I)^{-1}$. The new matrix is the same as the original one, but with the addition of $\\alpha$ to the diagonal. The diagonal entires of this matrix correspond to the variance of each input feature. We can see that $L^2$ regularization cuases the learning algorithm to percieve the input $X$ as having higher variance, which makes it shrink the weights on features whose covariance with the output target is low compared to this added variance."
      ],
      "metadata": {
        "id": "w7PEVoHR0ern"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RidgeLoss(Layer):\n",
        "    def __init__(self, alpha=1.0):\n",
        "        super().__init__()\n",
        "        self.alpha = Tensor(alpha, autograd=True)  # Regularization strength\n",
        "\n",
        "    def forward(self, pred, target, model):\n",
        "        # Compute the Mean Squared Error (MSE)\n",
        "        mse_loss = ((pred - target)*(pred - target)).sum(0)\n",
        "\n",
        "        # Compute the Ridge (L2) regularization term\n",
        "        ridge_loss = Tensor(0.0, autograd=True)\n",
        "        for param in model.get_parameters():\n",
        "            ridge_loss += Tensor((param.data ** 2).sum(), autograd=True)\n",
        "\n",
        "        # Combine MSE loss and Ridge regularization\n",
        "        total_loss = mse_loss + self.alpha * ridge_loss\n",
        "        return total_loss\n",
        "\n",
        "# Hyperparameters\n",
        "input_dim = 784\n",
        "output_dim = 10\n",
        "hidden_size = 50\n",
        "alpha = 0.01\n",
        "epochs = 100\n",
        "batch_size = 100\n",
        "lambda_reg = 1\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential([\n",
        "    Linear(input_dim, hidden_size),\n",
        "    Tanh(),\n",
        "    Linear(hidden_size, output_dim),\n",
        "    Sigmoid()\n",
        "])\n",
        "\n",
        "criterion = RidgeLoss(lambda_reg)\n",
        "optimizer = SGD(model.get_parameters(), alpha)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    correct_cnt = 0\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        batch_X = X_train[i:i+batch_size]\n",
        "        batch_y = y_train[i:i+batch_size]\n",
        "\n",
        "        input = Tensor(batch_X, autograd=True)\n",
        "        target = Tensor(batch_y, autograd=True)\n",
        "\n",
        "        # Forward pass\n",
        "        prediction = model.forward(input)\n",
        "        loss = criterion.forward(prediction, target, model)\n",
        "        total_loss += loss.data\n",
        "\n",
        "        for i in range(len(prediction.data)):\n",
        "            pred_label = prediction.data[i]\n",
        "            true_label = batch_y[i]\n",
        "            correct_cnt += int(np.argmax(pred_label.data) == np.argmax(true_label))\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "    accuracy = correct_cnt / float(len(y_train))\n",
        "    avg_loss = total_loss / (len(X_train) / batch_size)\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Accuracy: {accuracy}, Average Loss: {avg_loss}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "X_test_tensor = Tensor(X_test, autograd=True)\n",
        "y_pred = model.forward(X_test_tensor)\n",
        "test_accuracy = 0\n",
        "for i in range(len(y_pred.data)):\n",
        "    pred_label = y_pred.data[i]\n",
        "    true_label = y_test [i]\n",
        "    test_accuracy += int(np.argmax(pred_label.data) == np.argmax(true_label))\n",
        "test_accuracy = test_accuracy / float(len(y_test))\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "mse = ((y_pred.data - y_test) ** 2).mean()\n",
        "print(f\"Test MSE: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Btj_Xl68wmT",
        "outputId": "943edf04-46b1-4a45-920f-385947a7f2d4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Accuracy: 0.218, Average Loss: [151.14980994 151.82856124 152.87026549 152.32658156 153.29569342\n",
            " 153.71550238 150.40138061 152.9466566  152.21460277 153.98905984]\n",
            "Epoch 10, Accuracy: 0.92, Average Loss: [199.26083543 199.6837563  200.48314094 200.24990728 199.86259332\n",
            " 201.50202756 199.75383511 200.09991734 200.85029789 200.68123405]\n",
            "Epoch 20, Accuracy: 0.964, Average Loss: [237.09703836 237.49574915 237.78261246 237.60957519 237.43434781\n",
            " 238.15779056 237.34933208 237.49808163 237.80691848 237.94105403]\n",
            "Epoch 30, Accuracy: 0.979, Average Loss: [264.91860295 265.25474381 265.35436521 265.31848694 265.17820094\n",
            " 265.5597743  265.07975477 265.13401559 265.29853381 265.59751995]\n",
            "Epoch 40, Accuracy: 0.984, Average Loss: [286.20442692 286.52582521 286.49997669 286.56695953 286.38973139\n",
            " 286.69534539 286.34417183 286.33361676 286.4033552  286.75650289]\n",
            "Epoch 50, Accuracy: 0.985, Average Loss: [303.35812479 303.67111967 303.55752762 303.69041233 303.50361865\n",
            " 303.69803671 303.48432238 303.44345764 303.48008191 303.84881044]\n",
            "Epoch 60, Accuracy: 0.987, Average Loss: [317.09215547 317.39998668 317.25795262 317.3762779  317.20307625\n",
            " 317.35597473 317.21223971 317.15531976 317.17756081 317.55117727]\n",
            "Epoch 70, Accuracy: 0.989, Average Loss: [328.91836024 329.22308248 329.06636973 329.1395761  328.97085005\n",
            " 329.10101082 329.03388958 328.96601639 328.98400994 329.34803896]\n",
            "Epoch 80, Accuracy: 0.99, Average Loss: [339.04421404 339.34643402 339.18209587 339.22548553 339.08003298\n",
            " 339.19689748 339.15630366 339.08370401 339.09563158 339.42854425]\n",
            "Epoch 90, Accuracy: 0.99, Average Loss: [347.87750215 348.1782407  348.00852079 348.02945167 347.90436606\n",
            " 348.0160869  347.98708762 347.90921021 347.91888733 348.22700247]\n",
            "Test Accuracy: 0.854\n",
            "Test MSE: 0.02270070041393456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# $L^1$ Regularization - Lasso regression\n",
        "\n",
        "While $L^2$ weight decay is the most common form of weight decay, there are other ways to penalize the size of model parameters. Another option is to use the $L^1$ regularization, otherwise known as **lasso regression**.\n",
        "\n",
        "Formally, $L^1$ regularization on the model parameter $w$ is defined as\n",
        "\n",
        "$$\n",
        "  \\Omega(\\theta) = ||w||_1 = \\sum_i |w_i|\n",
        "$$\n",
        "\n",
        "that is, as the sum of absolute values of the individual parameters.\n",
        "\n",
        "As with $L^2$ weight decay, $L^1$ weight decay controls the strength of the regularization by scaling the penalty $\\Omega$ using a positive hyperparameter $\\alpha$. Thus, the regularized objective function $\\tilde{J} (w;X,y)$ is given by\n",
        "\n",
        "$$\n",
        "  \\tilde{J} (w;X,y) = \\alpha ||w||_1 + J(w;X,y)\n",
        "$$\n",
        "\n",
        "with the corresponding gradient\n",
        "\n",
        "$$\n",
        "  \\nabla_w \\tilde{J} (w;X,y) = \\alpha sign(w) + \\nabla_w J(X,y;w)\n",
        "$$\n",
        "\n",
        "where $sign(w)$ is simply the sign of $w$ applied element-wise.\n",
        "\n",
        "We can see that the regularization contribution to the gradient no longer scales linearly with each $w_i$; instead it is a constant factor with sign equal to $sign(w_i)$. One consequence of this form of gradient is that we will not necessarily see clean algebraic solutions to quadratic approximiations of $J(X,y;w)$ as we did for $L^2$ regularization.\n",
        "\n",
        "Our simple linear model has a quadratic cost function that we can represent via its Taylor series. Alternatively, we could imagine that this is a truncated Taylor series approximating the cost function of a more sophisticated model. The gradient in this setting is given by\n",
        "\n",
        "$$\n",
        "  \\nabla_w \\hat{J}(w) = H(w - w^*)\n",
        "$$\n",
        "\n",
        "where, again, $H$ is a Hessian matrix of $J$ with respect to $w$ evaluated at $w^*$\n",
        "\n",
        "Becuase the $L^1$ penalty does not admit clean algebraic expressions in the case of a fully general Hessian, we will also make the further simplifying assumption that the Hessian is diagonal, $H = diag([H_{1,1}, \\cdots, H_{n,n}])$ where $H_{i,i} > 0$. This assumption holds if the data for the linear regression problem has been preprocessed to remove all correlation between input features, which is accomplished using PCA.\n",
        "\n",
        "Our quadratic approximation of the $L^1$ regularizaed objective  function decomposes into a sum over the parameters.\n",
        "\n",
        "$$\n",
        "  \\hat{J}(w;X,y) - J(w^*;x,y) + \\sum_i [\\frac{1}{2} H_{i,i}(w_i - w_i^*)^2 + \\alpha |w_i|]\n",
        "$$\n",
        "\n",
        "The problem of minmizing the cost function has an analytical solution with the following form:\n",
        "\n",
        "$$\n",
        "  w_i = sign(w^*) max \\{ |w_i| - \\frac{\\alpha}{H_{i,i}}, 0\\}\n",
        "$$\n",
        "\n",
        "Consider the situation where $w_i^* > 0$ for all $i$. There are two possible outcomes:\n",
        "\n",
        "1. The case where $w_i^* \\le \\frac{\\alpha}{H_{i,i}}$. Here the optimal value of $w_i$ under the regularized objective is simply $w_i = 0$. This occurs because the contribution of $J(w;X,y)$ to the regularized objective $\\hat{J}(w;X,y)$ is overwhelmed - in direction $i$ - by the $L^1$ regularization, which puhses the value of $w_i$ to zero.\n",
        "2.  The case where $w_i^* > \\frac{\\alpha}{H_{i,i}}$. In this case, the regularization does not move the potimal value of $w_i$ to zero but instead just shifts it in the direction by a distance equal to $\\frac{\\alpha}{H_{i,i}}$\n",
        "\n",
        "A similar process happens when $w^*_i < 0$, but with the $L^1$ penalty making $w_i$ less negative by $\\frac{\\alpha}{H_{i,i}}$, or 0.\n",
        "\n",
        "In comparison to $L^2$ regularization, $L^1$ regularization results in a solution that is more **sparse**. Spartisity in this context refers to the fact that some parameters have an optimial value of zero. The sparsity of $L^1$ regularization is a qualitatively different behaviour than arises with $L^2$ regularization.\n",
        "\n",
        "This equation gave the solution for $\\tilde{w} for $L^2$ reguarlization:\n",
        "\n",
        "$$\n",
        "  \\tilde{w} = (H + \\alpha I)^{-1} Hw^*\n",
        "$$\n",
        "\n",
        "If we revisit that equation using the assumption of diagonal and positive semidefinite Hessian $H$ that we introduced for our analysis of $L^1$ regularization, we find that\n",
        "\n",
        "$$\n",
        "   \\tilde{w} = \\frac{H_{i,i}}{H_{i,i} + \\alpha} w_i^*\n",
        "$$\n",
        "\n",
        "If $w_i$ is nonzero, then $\\tilde{w}_i$ remains nonzero. This demonstrates that $L^2$ regularization does not cause the parameters to become spare, while $L^1$ regularization may do so for large enough $\\alpha$.\n",
        "\n",
        "$L^2$ regualirzation is equivalent to MAP Bayesian inference with a Gaussian prior on the weights. For $L^1$ regularization the penalty $ \\alpha \\Omega (w) = \\alpha \\sum_i |w_i| $ used to regularize the cost function is equivalent to the log-prior term that is maximized by MAP Bayesian inference when the prior is an isotropic Laplace distribution over $w \\in \\mathbb{R}^n$:\n",
        "\n",
        "$$\n",
        "  log p(w) = \\sum_i \\log Laplace(w_i;0,\\frac{1}{a}) \\\\\n",
        "  = -a ||w||_1 + n \\log \\alpha - n \\log 2\n",
        "$$\n",
        "\n",
        "From the point of view of learning via maximization with respect to $w$, we can ignore $\\log \\alpha - \\log 2$ terms because they do not depend on $w$.\n",
        "\n",
        "Remember: An even simpler version is the **isotropic** Gaussian distribution, whose covariance matrix is a scalar times the identity matrix."
      ],
      "metadata": {
        "id": "CNZAC9McGhl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LassoLoss(Layer):\n",
        "    def __init__(self, alpha=1.0):\n",
        "        super().__init__()\n",
        "        self.alpha = Tensor(alpha, autograd=True)  # Regularization strength\n",
        "\n",
        "    def forward(self, pred, target, model):\n",
        "        # Compute the Mean Squared Error (MSE)\n",
        "        mse_loss = ((pred - target) * (pred - target)).sum(0)\n",
        "\n",
        "        # Compute the Lasso (L1) regularization term\n",
        "        lasso_loss = Tensor(0.0, autograd=True)\n",
        "        for param in model.get_parameters():\n",
        "            lasso_loss += Tensor(np.abs(param.data).sum(), autograd=True)\n",
        "\n",
        "        # Combine MSE loss and Lasso regularization\n",
        "        total_loss = mse_loss + self.alpha * lasso_loss\n",
        "        return total_loss\n",
        "\n",
        "# Hyperparameters\n",
        "input_dim = 784\n",
        "output_dim = 10\n",
        "hidden_size = 50\n",
        "alpha = 0.01\n",
        "epochs = 100\n",
        "batch_size = 100\n",
        "lambda_reg = 1\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential([\n",
        "    Linear(input_dim, hidden_size),\n",
        "    Tanh(),\n",
        "    Linear(hidden_size, output_dim),\n",
        "    Sigmoid()\n",
        "])\n",
        "\n",
        "criterion = LassoLoss(lambda_reg)\n",
        "optimizer = SGD(model.get_parameters(), alpha)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    correct_cnt = 0\n",
        "    for i in range(0, len(X_train), batch_size):\n",
        "        batch_X = X_train[i:i+batch_size]\n",
        "        batch_y = y_train[i:i+batch_size]\n",
        "\n",
        "        input = Tensor(batch_X, autograd=True)\n",
        "        target = Tensor(batch_y, autograd=True)\n",
        "\n",
        "        # Forward pass\n",
        "        prediction = model.forward(input)\n",
        "        loss = criterion.forward(prediction, target, model)\n",
        "        total_loss += loss.data\n",
        "\n",
        "        for i in range(len(prediction.data)):\n",
        "            pred_label = prediction.data[i]\n",
        "            true_label = batch_y[i]\n",
        "            correct_cnt += int(np.argmax(pred_label.data) == np.argmax(true_label))\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "    accuracy = correct_cnt / float(len(y_train))\n",
        "    avg_loss = total_loss / (len(X_train) / batch_size)\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Accuracy: {accuracy}, Average Loss: {avg_loss}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "X_test_tensor = Tensor(X_test, autograd=True)\n",
        "y_pred = model.forward(X_test_tensor)\n",
        "test_accuracy = 0\n",
        "for i in range(len(y_pred.data)):\n",
        "    pred_label = y_pred.data[i]\n",
        "    true_label = y_test [i]\n",
        "    test_accuracy += int(np.argmax(pred_label.data) == np.argmax(true_label))\n",
        "test_accuracy = test_accuracy / float(len(y_test))\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "mse = ((y_pred.data - y_test) ** 2).mean()\n",
        "print(f\"Test MSE: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NmOX-myGyKa",
        "outputId": "e3d6a4d4-e3ab-4540-aaf3-b153c92c54f8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Accuracy: 0.203, Average Loss: [1803.72702978 1803.43550497 1802.81006316 1801.10295619 1802.14006753\n",
            " 1801.81631922 1802.28535311 1803.97387147 1801.79079882 1804.52030859]\n",
            "Epoch 10, Accuracy: 0.913, Average Loss: [1965.37804101 1965.74152099 1966.55385917 1966.27247352 1966.21412502\n",
            " 1967.47787618 1965.99973786 1966.62955769 1966.97365152 1970.48844513]\n",
            "Epoch 20, Accuracy: 0.964, Average Loss: [2076.15847128 2076.50152311 2076.83546918 2076.66772604 2076.60086932\n",
            " 2077.22109548 2076.54075072 2076.79492616 2076.98531746 2077.66164822]\n",
            "Epoch 30, Accuracy: 0.98, Average Loss: [2152.21874875 2152.52027732 2152.58057775 2152.54336297 2152.51528918\n",
            " 2152.86425708 2152.49186719 2152.48821143 2152.69272137 2153.13352728]\n",
            "Epoch 40, Accuracy: 0.985, Average Loss: [2206.14368068 2206.43164528 2206.37951588 2206.41045741 2206.3456064\n",
            " 2206.51568285 2206.3412459  2206.28079002 2206.4924667  2206.77119811]\n",
            "Epoch 50, Accuracy: 0.988, Average Loss: [2245.51227023 2245.76145156 2245.67002219 2245.75811975 2245.67397269\n",
            " 2245.79900407 2245.65376123 2245.59124808 2245.79251908 2245.99310249]\n",
            "Epoch 60, Accuracy: 0.99, Average Loss: [2276.25041626 2276.4767963  2276.34145396 2276.48322025 2276.38198715\n",
            " 2276.46376018 2276.37406487 2276.30334021 2276.44999791 2276.66071876]\n",
            "Epoch 70, Accuracy: 0.99, Average Loss: [2300.63464104 2300.85145717 2300.69664405 2300.85827059 2300.69254802\n",
            " 2300.80815102 2300.75023251 2300.67347361 2300.80379552 2301.00589825]\n",
            "Epoch 80, Accuracy: 0.99, Average Loss: [2320.66082094 2320.87268108 2320.70656007 2320.87918647 2320.6999692\n",
            " 2320.81304483 2320.77148127 2320.69106523 2320.81432665 2320.99485528]\n",
            "Epoch 90, Accuracy: 0.991, Average Loss: [2337.74854429 2337.9568558  2337.78510135 2337.96291333 2337.77885514\n",
            " 2337.88778008 2337.85627833 2337.77300489 2337.89261306 2338.02066899]\n",
            "Test Accuracy: 0.837\n",
            "Test MSE: 0.02410813697394257\n"
          ]
        }
      ]
    }
  ]
}